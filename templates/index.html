<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chat with Dilbert</title>
    <link rel="stylesheet" href="/static/style.css">
</head>

<body>
    <div id="container">
        <h1>DILBOT</h1>
        <img id="dilbertImage" src="/static/dilbert.jpg" alt="Dilbert">
        <button id="recordButton" class="stop">TALK</button>
        <progress id="recordProgress" value="0" max="30"></progress>
        <div id="loading"></div>
        <div id="errorMessage"></div>
        <div class="audio-container">
            <audio id="audioResponse" controls></audio>
            <button id="toggleTranscriptButton">Show Transcript</button>
        </div>
        <div id="conversation" class="hidden">
            <div id="transcript" class="hidden">
                <p><strong>User Message:</strong> <span id="userMessage"></span></p>
                <p><strong>Dilbot Response:</strong> <span id="botMessage"></span></p>
            </div>
        </div>
    </div>
    <script>
        document.addEventListener('DOMContentLoaded', () => {
            let mediaRecorder;
            let audioChunks = [];
            let isRecording = false;
            let startTime;
            let timerInterval;
            let mimeType;

            const recordButton = document.getElementById('recordButton');
            const recordProgress = document.getElementById('recordProgress');
            const loadingIndicator = document.getElementById('loading');
            const errorMessage = document.getElementById('errorMessage');
            const userMessageElement = document.getElementById('userMessage');
            const botMessageElement = document.getElementById('botMessage');
            const conversationElement = document.getElementById('conversation');
            const toggleTranscriptButton = document.getElementById('toggleTranscriptButton');
            const transcriptElement = document.getElementById('transcript');
            const dilbertImage = document.getElementById('dilbertImage');
            const audioResponse = document.getElementById('audioResponse');

            function logError(error) {
                console.error(error);
                errorMessage.textContent = `Error: ${error.message}`;
                errorMessage.style.display = 'block';
            }

            async function startRecording() {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

                    // Detect supported MIME type
                    if (MediaRecorder.isTypeSupported('audio/webm')) {
                        mimeType = 'audio/webm';
                    } else if (MediaRecorder.isTypeSupported('audio/mp4')) {
                        mimeType = 'audio/mp4';
                    } else if (MediaRecorder.isTypeSupported('audio/wav')) {
                        mimeType = 'audio/wav';
                    } else {
                        throw new Error('None of the supported MIME types are available.');
                    }

                    mediaRecorder = new MediaRecorder(stream, { mimeType: mimeType });

                    mediaRecorder.ondataavailable = event => {
                        audioChunks.push(event.data);
                    };

                    mediaRecorder.onstop = async () => {
                        const audioBlob = new Blob(audioChunks, { type: mimeType });
                        audioChunks = [];
                        await sendAudioToServer(audioBlob);
                    };

                    mediaRecorder.start();
                    startTime = Date.now();
                    isRecording = true;
                    recordButton.textContent = 'STOP';
                    recordButton.classList.remove('stop');
                    recordButton.classList.add('record');
                    startTimer();
                } catch (error) {
                    logError(error);
                }
            }

            function stopRecording() {
                if (!isRecording) return;
                mediaRecorder.stop();
                isRecording = false;
                recordButton.textContent = 'TALK';
                recordButton.classList.remove('record');
                recordButton.classList.add('stop');
                clearInterval(timerInterval);
                recordProgress.value = 0;

                const duration = (Date.now() - startTime) / 1000;
                if (duration < 1) {
                    errorMessage.textContent = 'Recording is too short!';
                    errorMessage.style.display = 'block';
                }
            }

            function toggleRecording() {
                if (isRecording) {
                    stopRecording();
                } else {
                    startRecording();
                }
            }

            function startTimer() {
                const maxTime = 30; // 30 seconds
                timerInterval = setInterval(() => {
                    const elapsedTime = (Date.now() - startTime) / 1000;
                    recordProgress.value = elapsedTime;

                    if (elapsedTime >= maxTime) {
                        stopRecording();
                    }
                }, 100);
            }

            recordButton.addEventListener('click', toggleRecording);
            recordButton.addEventListener('touchstart', toggleRecording);

            toggleTranscriptButton.addEventListener('click', () => {
                transcriptElement.classList.toggle('hidden');
                toggleTranscriptButton.textContent = transcriptElement.classList.contains('hidden') ? 'Show Transcript' : 'Hide Transcript';
            });

            audioResponse.addEventListener('play', () => {
                dilbertImage.style.animation = 'shake 0.5s';
                dilbertImage.style.animationIterationCount = 'infinite';
            });

            audioResponse.addEventListener('pause', () => {
                dilbertImage.style.animation = 'none';
            });

            async function sendAudioToServer(audioBlob) {
                loadingIndicator.style.display = 'block';
                errorMessage.style.display = 'none';

                const formData = new FormData();
                formData.append('file', audioBlob, `recording.${mimeType.split('/')[1]}`);

                try {
                    const response = await fetch('/talk', {
                        method: 'POST',
                        body: formData
                    });

                    if (response.ok) {
                        const responseData = await response.json();
                        userMessageElement.textContent = responseData.user_message;
                        botMessageElement.textContent = responseData.bot_message;

                        const audioBinary = atob(responseData.audio);
                        const arrayBuffer = new ArrayBuffer(audioBinary.length);
                        const bufferView = new Uint8Array(arrayBuffer);
                        for (let i = 0; i < audioBinary.length; i++) {
                            bufferView[i] = audioBinary.charCodeAt(i);
                        }
                        const audioBlob = new Blob([arrayBuffer], { type: 'audio/mpeg' });
                        const audioUrl = URL.createObjectURL(audioBlob);
                        audioResponse.src = audioUrl;

                        audioResponse.oncanplaythrough = () => {
                            loadingIndicator.style.display = 'none';
                            audioResponse.play();
                        };

                        conversationElement.classList.remove('hidden');
                    } else {
                        throw new Error(response.statusText);
                    }
                } catch (error) {
                    logError(error);
                    loadingIndicator.style.display = 'none';
                }
            }
        });
    </script>
</body>

</html>